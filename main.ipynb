{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:47:59.391012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/brca_metabric_clinical_data.tsv', sep='\\t')\n",
    "df.to_csv('./dataset/brca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Study ID', 'Patient ID', 'Sample ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tumor Stage\n",
       "2.0    979\n",
       "1.0    630\n",
       "3.0    144\n",
       "0.0     24\n",
       "4.0     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient's Vital Status\n",
       "Living                  837\n",
       "Died of Disease         646\n",
       "Died of Other Causes    497\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2509 entries, 0 to 2508\n",
      "Data columns (total 36 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Age at Diagnosis                2498 non-null   float64\n",
      " 1   Type of Breast Surgery          1955 non-null   object \n",
      " 2   Cancer Type                     2509 non-null   object \n",
      " 3   Cancer Type Detailed            2509 non-null   object \n",
      " 4   Cellularity                     1917 non-null   object \n",
      " 5   Chemotherapy                    1980 non-null   object \n",
      " 6   Pam50 + Claudin-low subtype     1980 non-null   object \n",
      " 7   Cohort                          2498 non-null   float64\n",
      " 8   ER status measured by IHC       2426 non-null   object \n",
      " 9   ER Status                       2469 non-null   object \n",
      " 10  Neoplasm Histologic Grade       2388 non-null   float64\n",
      " 11  HER2 status measured by SNP6    1980 non-null   object \n",
      " 12  HER2 Status                     1980 non-null   object \n",
      " 13  Tumor Other Histologic Subtype  2374 non-null   object \n",
      " 14  Hormone Therapy                 1980 non-null   object \n",
      " 15  Inferred Menopausal State       1980 non-null   object \n",
      " 16  Integrative Cluster             1980 non-null   object \n",
      " 17  Primary Tumor Laterality        1870 non-null   object \n",
      " 18  Lymph nodes examined positive   2243 non-null   float64\n",
      " 19  Mutation Count                  2358 non-null   float64\n",
      " 20  Nottingham prognostic index     2287 non-null   float64\n",
      " 21  Oncotree Code                   2509 non-null   object \n",
      " 22  Overall Survival (Months)       1981 non-null   float64\n",
      " 23  Overall Survival Status         1981 non-null   object \n",
      " 24  PR Status                       1980 non-null   object \n",
      " 25  Radio Therapy                   1980 non-null   object \n",
      " 26  Relapse Free Status (Months)    2388 non-null   float64\n",
      " 27  Relapse Free Status             2488 non-null   object \n",
      " 28  Number of Samples Per Patient   2509 non-null   int64  \n",
      " 29  Sample Type                     2509 non-null   object \n",
      " 30  Sex                             2509 non-null   object \n",
      " 31  3-Gene classifier subtype       1764 non-null   object \n",
      " 32  TMB (nonsynonymous)             2509 non-null   float64\n",
      " 33  Tumor Size                      2360 non-null   float64\n",
      " 34  Tumor Stage                     1788 non-null   float64\n",
      " 35  Patient's Vital Status          1980 non-null   object \n",
      "dtypes: float64(11), int64(1), object(24)\n",
      "memory usage: 705.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at Diagnosis           11\n",
      "Type of Breast Surgery    554\n",
      "Cancer Type                 0\n",
      "Cancer Type Detailed        0\n",
      "Cellularity               592\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_nan_columns = df.isnull().sum()\n",
    "print(n_nan_columns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tumor Stage\n",
       "2.0    624\n",
       "1.0    369\n",
       "3.0     92\n",
       "4.0      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tumor Stage\n",
       "2.0    624\n",
       "1.0    369\n",
       "3.0     92\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.iloc[:, -2] != 4.0]\n",
    "df = df[df.iloc[:, -2] != 0.0]\n",
    "df.iloc[:, -2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -2]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.88      0.92        68\n",
      "         2.0       0.86      0.97      0.91       134\n",
      "         3.0       0.67      0.13      0.22        15\n",
      "\n",
      "    accuracy                           0.88       217\n",
      "   macro avg       0.83      0.66      0.68       217\n",
      "weighted avg       0.88      0.88      0.87       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.88      0.93        68\n",
      "         2.0       0.88      0.99      0.93       134\n",
      "         3.0       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.91       217\n",
      "   macro avg       0.95      0.71      0.76       217\n",
      "weighted avg       0.92      0.91      0.89       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.74      0.78        68\n",
      "         2.0       0.80      0.92      0.86       134\n",
      "         3.0       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.81       217\n",
      "   macro avg       0.87      0.62      0.66       217\n",
      "weighted avg       0.82      0.81      0.80       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.88      0.87        68\n",
      "         2.0       0.87      0.90      0.89       134\n",
      "         3.0       0.62      0.33      0.43        15\n",
      "\n",
      "    accuracy                           0.86       217\n",
      "   macro avg       0.78      0.71      0.73       217\n",
      "weighted avg       0.85      0.86      0.85       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: 0.8571428571428571\n",
      "poly: 0.7235023041474654\n",
      "rbf: 0.6175115207373272\n",
      "sigmoid: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm_model = SVC(kernel=kernel, C=best_params['C'], gamma=best_params['gamma'])\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{kernel}:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        68\n",
      "           1       0.94      0.96      0.95       134\n",
      "           2       0.67      0.67      0.67        15\n",
      "\n",
      "    accuracy                           0.94       217\n",
      "   macro avg       0.86      0.86      0.86       217\n",
      "weighted avg       0.94      0.94      0.94       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_transformed = le.fit_transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train_transformed)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test_transformed, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        68\n",
      "           1       0.94      0.96      0.95       134\n",
      "           2       0.64      0.60      0.62        15\n",
      "\n",
      "    accuracy                           0.94       217\n",
      "   macro avg       0.86      0.84      0.85       217\n",
      "weighted avg       0.93      0.94      0.93       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [None, 3, 5, 7],\n",
    "    'n_estimators': [10, 100, 200, 300]\n",
    "}\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_transformed = le.fit_transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(classification_report(y_test_transformed, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.63      0.74        68\n",
      "           1       0.77      0.82      0.80       134\n",
      "           2       0.30      0.53      0.38        15\n",
      "\n",
      "    accuracy                           0.74       217\n",
      "   macro avg       0.66      0.66      0.64       217\n",
      "weighted avg       0.78      0.74      0.75       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(X_train, y_train_transformed)\n",
    "\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "print(classification_report(y_test_transformed, y_pred_adaboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        68\n",
      "           1       0.86      0.98      0.91       134\n",
      "           2       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.88       217\n",
      "   macro avg       0.78      0.66      0.68       217\n",
      "weighted avg       0.87      0.88      0.87       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(classification_report(y_test_transformed, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        68\n",
      "           1       0.92      0.98      0.95       134\n",
      "           2       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.94       217\n",
      "   macro avg       0.90      0.80      0.83       217\n",
      "weighted avg       0.93      0.94      0.93       217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='soft')\n",
    "ensemble_model.fit(X_train, y_train_transformed)\n",
    "\n",
    "\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_transformed, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Hard Voting) for each fold: [0.89908257 0.88990826 0.83486239 0.89908257 0.79816514 0.89814815\n",
      " 0.94444444 0.93518519 0.96296296 0.90740741]\n",
      "Accuracy (Soft Voting) for each fold: [0.88990826 0.89908257 0.87155963 0.89908257 0.86238532 0.89814815\n",
      " 0.94444444 0.93518519 0.9537037  0.92592593]\n",
      "Mean Accuracy (Hard Voting): 0.8969249065579341\n",
      "Mean Accuracy (Soft Voting): 0.9079425756031261\n",
      "Max Accuracy (Hard Voting): 0.9629629629629629\n",
      "Max Accuracy (Soft Voting): 0.9537037037037037\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "\n",
    "ensemble_hard = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='hard')\n",
    "ensemble_soft = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='soft')\n",
    "\n",
    "cv_scores_hard = cross_val_score(ensemble_hard, X, y, cv=10)\n",
    "cv_scores_soft = cross_val_score(ensemble_soft, X, y, cv=10)\n",
    "\n",
    "print(\"Accuracy (Hard Voting) for each fold:\", cv_scores_hard)\n",
    "print(\"Accuracy (Soft Voting) for each fold:\", cv_scores_soft)\n",
    "\n",
    "print(\"Mean Accuracy (Hard Voting):\", cv_scores_hard.mean())\n",
    "print(\"Mean Accuracy (Soft Voting):\", cv_scores_soft.mean())\n",
    "\n",
    "print(\"Max Accuracy (Hard Voting):\", cv_scores_hard.max())\n",
    "print(\"Max Accuracy (Soft Voting):\", cv_scores_soft.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Hard Voting) - Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.92      0.95        90\n",
      "         2.0       0.86      0.96      0.91       111\n",
      "         3.0       0.50      0.25      0.33        16\n",
      "\n",
      "    accuracy                           0.89       217\n",
      "   macro avg       0.78      0.71      0.73       217\n",
      "weighted avg       0.88      0.89      0.88       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.91      0.94        81\n",
      "         2.0       0.90      0.96      0.93       122\n",
      "         3.0       0.64      0.50      0.56        14\n",
      "\n",
      "    accuracy                           0.91       217\n",
      "   macro avg       0.84      0.79      0.81       217\n",
      "weighted avg       0.91      0.91      0.91       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.94      0.95        70\n",
      "         2.0       0.89      0.95      0.92       129\n",
      "         3.0       0.60      0.33      0.43        18\n",
      "\n",
      "    accuracy                           0.90       217\n",
      "   macro avg       0.82      0.74      0.77       217\n",
      "weighted avg       0.89      0.90      0.89       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.93      0.94        82\n",
      "         2.0       0.90      0.93      0.92       121\n",
      "         3.0       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.91       217\n",
      "   macro avg       0.84      0.81      0.82       217\n",
      "weighted avg       0.91      0.91      0.91       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.93      0.96        71\n",
      "         2.0       0.88      0.94      0.91       125\n",
      "         3.0       0.62      0.48      0.54        21\n",
      "\n",
      "    accuracy                           0.89       217\n",
      "   macro avg       0.83      0.78      0.80       217\n",
      "weighted avg       0.89      0.89      0.89       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.95      0.98        85\n",
      "         2.0       0.85      0.99      0.92       110\n",
      "         3.0       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       217\n",
      "   macro avg       0.91      0.75      0.79       217\n",
      "weighted avg       0.91      0.91      0.89       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.97      0.95        72\n",
      "         2.0       0.89      0.91      0.90       124\n",
      "         3.0       0.60      0.43      0.50        21\n",
      "\n",
      "    accuracy                           0.88       217\n",
      "   macro avg       0.81      0.77      0.78       217\n",
      "weighted avg       0.88      0.88      0.88       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.94      0.95        70\n",
      "         2.0       0.93      0.94      0.93       136\n",
      "         3.0       0.50      0.45      0.48        11\n",
      "\n",
      "    accuracy                           0.92       217\n",
      "   macro avg       0.79      0.78      0.79       217\n",
      "weighted avg       0.92      0.92      0.92       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.90      0.93        69\n",
      "         2.0       0.90      0.97      0.94       134\n",
      "         3.0       0.78      0.50      0.61        14\n",
      "\n",
      "    accuracy                           0.92       217\n",
      "   macro avg       0.88      0.79      0.83       217\n",
      "weighted avg       0.92      0.92      0.91       217\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.95      0.96        80\n",
      "         2.0       0.92      0.98      0.95       126\n",
      "         3.0       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.94       217\n",
      "   macro avg       0.96      0.76      0.81       217\n",
      "weighted avg       0.94      0.94      0.93       217\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "ensemble_hard = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='hard')\n",
    "\n",
    "cv_scores_hard = cross_val_score(ensemble_hard, X, y, cv=10)\n",
    "\n",
    "for fold in range(10):\n",
    "    X_train_fold, X_test_fold, y_train_fold, y_test_fold = train_test_split(X, y, test_size=0.2, random_state=fold)\n",
    "    \n",
    "    ensemble_hard.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_hard = ensemble_hard.predict(X_test_fold)\n",
    "    report_hard = classification_report(y_test_fold, y_pred_hard)\n",
    "    print(f\"Classification Report (Hard Voting) - Fold {fold+1}:\\n{report_hard}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Hard Voting) for each fold: [0.93969849 0.91959799 0.90954774 0.98492462 0.92462312 0.9798995\n",
      " 0.96969697 0.98484848 0.97474747 0.97979798]\n",
      "Mean Accuracy (Hard Voting): 0.9567382366377339\n",
      "Max Accuracy (Hard Voting): 0.9849246231155779\n"
     ]
    }
   ],
   "source": [
    "df_upsampled = df[df.iloc[:, -2] == 3.0]\n",
    "df_upsampled = resample(df_upsampled, replace=True, n_samples=df[df.iloc[:, -2] != 3.0].shape[0], random_state=42)\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df[df.iloc[:, -2] != 3.0], df_upsampled])\n",
    "X_upsampled = df_combined.iloc[:, :-2]\n",
    "y_upsampled = df_combined.iloc[:, -2]\n",
    "\n",
    "X_upsampled = pd.get_dummies(X_upsampled)\n",
    "X_upsampled = scaler.transform(X_upsampled)\n",
    "\n",
    "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "ensemble_hard_upsampled = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='hard')\n",
    "cv_scores_hard = cross_val_score(ensemble_hard, X_upsampled, y_upsampled, cv=10)\n",
    "\n",
    "print(\"Accuracy (Hard Voting) for each fold:\", cv_scores_hard)\n",
    "print(\"Mean Accuracy (Hard Voting):\", cv_scores_hard.mean())\n",
    "print(\"Max Accuracy (Hard Voting):\", cv_scores_hard.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Hard Voting) - Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.93      0.95        84\n",
      "         2.0       0.95      0.90      0.92       116\n",
      "         3.0       0.95      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.94      0.95       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.92      0.94        84\n",
      "         2.0       0.94      0.89      0.91       116\n",
      "         3.0       0.95      1.00      0.97       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.95      0.93      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.93      0.95        84\n",
      "         2.0       0.95      0.91      0.93       116\n",
      "         3.0       0.96      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.96       398\n",
      "   macro avg       0.96      0.94      0.95       398\n",
      "weighted avg       0.96      0.96      0.96       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.94      0.96        84\n",
      "         2.0       0.95      0.89      0.92       116\n",
      "         3.0       0.95      1.00      0.97       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.94      0.95       398\n",
      "weighted avg       0.96      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.92      0.94        84\n",
      "         2.0       0.94      0.88      0.91       116\n",
      "         3.0       0.94      1.00      0.97       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.95      0.93      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.94      0.96        84\n",
      "         2.0       0.95      0.90      0.92       116\n",
      "         3.0       0.95      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.96       398\n",
      "   macro avg       0.96      0.95      0.95       398\n",
      "weighted avg       0.96      0.96      0.96       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.93      0.95        84\n",
      "         2.0       0.95      0.90      0.92       116\n",
      "         3.0       0.95      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.94      0.95       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.93      0.95        84\n",
      "         2.0       0.95      0.90      0.92       116\n",
      "         3.0       0.95      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.94      0.95       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.92      0.94        84\n",
      "         2.0       0.94      0.90      0.92       116\n",
      "         3.0       0.96      1.00      0.98       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.95      0.94      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n",
      "Classification Report (Hard Voting) - Fold 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.92      0.94        84\n",
      "         2.0       0.94      0.89      0.91       116\n",
      "         3.0       0.95      1.00      0.97       198\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.95      0.93      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "ensemble_hard = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model), ('svm', svm_model)], voting='hard')\n",
    "\n",
    "cv_scores_hard = cross_val_score(ensemble_hard, X, y, cv=10)\n",
    "\n",
    "for fold in range(10):\n",
    "    X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    ensemble_hard.fit(X_train_upsampled, y_train_upsampled)\n",
    "    y_pred_hard = ensemble_hard.predict(X_test_upsampled)\n",
    "    report_hard = classification_report(y_test_upsampled, y_pred_hard)\n",
    "    print(f\"Classification Report (Hard Voting) - Fold {fold+1}:\\n{report_hard}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
